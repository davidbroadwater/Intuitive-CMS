__author__ = 'elisabethpaulson'

from SBA_tweet_sklearn import *
from SBA_text_analysis_gensim import *

####### RELATE TWITTER DATA TO SBA WEB CONTENT #################

# IMPORT CORPUS FROM FEMA WEBSITE
corpus=corpora.MmCorpus("SBA.mm")

# # TF-IDF
# corpus_tfidf=tfidf2[corpus]
#
# #Run LSI, HDP, or LDA model on corpus from FEMA website. Uses topics generated by tweets and scores FEMA content according to these topics
# ### FIND WHICH DOCUMENTS FROM FEMA SITE ARE SIMILAR TO TOPICS FROM TWEETS
# SBAcorpus_lda=lda2[corpus_tfidf]
#
# #dictionary=corpora.Dictionary.load("SBA.dict")
#
# m=-1
# for doc in corpus_lda: #scans through content on SBA's site
#     m=m+1
#     doc=sorted(doc,key=lambda  item: -item[1])
#     if doc!=[]:
#         if doc[0][1]>.5: #specify a similarity score threshold
#             print standard_links[m],' relates to topic ', doc[0][0]

dictionary=corpora.Dictionary.load("SBA.dict")

### FIND WHICH TWEETS BEST MATCH EACH TOPIC
for i in range(n_clusters):
    print'TOPIC ', i, topic_phrases[i]
    # FIND WHAT TOPIC BEST MATCHES TERM
    doc=''
    for word in topic_phrases[i]:
        doc+=word
    ##### # FIND WHAT TOPIC BEST MATCHES GIVEN TERM
    vec_bow=dictionary.doc2bow(doc.lower().split())
    print vec_bow
    vec_lda=SBAlda[vec_bow]
    print(vec_lda) # print vector that scores each document according to how well it matches query

    # WHICH WHICH DOCUMENT BEST MATCHES TERM
    index=similarities.MatrixSimilarity(SBAlda[SBAcorpus])
    print index
    index.save('SBA.index')
    #index=similarities.MatrixSimilarity.load('FEMA.index')

    # PRINT TOP 5 FEMA DOCUMENTS THAT BEST MATCH QUERY TERM
    sims=index[vec_lda]
    sims=sorted(enumerate(sims),key=lambda  item: -item[1])
    print sims[:5]
    for i in sims[:5]:
       print(standard_descriptions[i[0]])
       print(standard_links[i[0]])